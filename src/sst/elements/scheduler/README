--------------------------------------------------
    How to Use The Scheduler Component With SST
--------------------------------------------------

The scheduler component reads in a trace (usually .sim) file, which consists
of four entries: arrival time, number of processors, actual run time (the
amount of time the job actually ran for) and estimated run time (the estimated
job given when the job was submitted, if any). The optional entries are:
- comm <intra-job (task) communication file in matrixMarket format>
- center <center task number of the job>
- coord <task communication file> <task coordinates file in matrixMarket>
- mesh <x> <y> <z>: job with stencil communication with x,y,z dimensions
If no communication structure is given, all-to-all communication is assumed.
The .sim file can be created from the Parallel Workloads Archive .swf format
using convertTrace.py. The output from the simulatons is stored in a .time
file (stating information about each job, particularly what time and in what
order each was run) and a .alloc file (gives allocation information about each 
job such as number of processors and total pairwise L1 distance--note that
SimpleMachine does not support .alloc files). If the original simulation was
example.sim, the outputs will be example.sim.time and example.sim.alloc. All
the files necesary to do this, both example simulations from the PWA and python
scripts to create helper files, are in the /simulations subfolder. Note that as
if this writing, simulations with jobs that require more than
(UNSIGNED_LONG_MAX)/10^12 bits will not run correctly. If there are 64 bits in
a long, this corresponds to 7 months after the start (time 18446744).

--------------------------------------------------
    Running SST
--------------------------------------------------

There are two options to run SST: 

1) ./sst sstInput.py --verbose
2) ./sst --sdl-file=example.sdl --verbose 

where --verbose is optional. sst is in the /core folder of the installation.
A python input file for a given instance can be generated running makeInput.py
by modifying the parameters at the beginning of the file. The command is:

python makeInput.py

Alternatively, an sdl file for a given instance can be generated using 
makeSDL.pl, with the first argument the number of processors, second argument
the name of the trace file (the .sim file), and the third through fifth
argument the name of the scheduler, machine, and allocator respectively. The
scheduler, machine, and allocator can be modified from their original version
using brackets, i.e. pqueue[shortfirst] is a priority queue that runs the
shortest jobs first, whereas pqueue defaults to a fifo priority queue. Note
that the Perl script gives the SDL as terminal output and it must be piped into
the file directly. An example command to generate an SDL file named
"testsdl.sdl" with the easy scheduler (with priorities based on largest
 number of required processors), on a 24x167x1 mesh with a random
allocator would be: 

./makeSDL.pl 4008 LLNL.sim easy["largefirst"] mesh[24,167] random > testsdl.sdl 

--------------------------------------------------
    Arguments to the Scheduler Component
--------------------------------------------------


             Schedulers:

  Most schedulers take one optional argument determining the order in which
they keep lists of waiting jobs (beyond their own ordering; i.e. EASY only
uses the argument to determine what order jobs would be backfilled in,
whereas pqueue schedules strictly in the given ordering).  This defaults
to fifo in all cases, but an argument can be given to name a comparator,
i.e., pqueue[smallfirst].  The prioritize scheduler takes one additional,
optional argument.

pqueue - a basic scheduler which keeps a priority queue of jobs that are
available to run. The queue is kept in order based on the given comparator,
fifo by default. 

easy - based on the EASY scheduler.  Gives guaranteed times to the first job
which cannot be violated; backfilling can occur otherwise.  

  These three are all based on the Conservative Scheduler, which gives
guarantees to all jobs and only backfills when the backfilling does not
disturb any other job's guarantee:

cons - Just compresses the jobs (makes the guarantees better when possible),
does not do any backfilling.

prioritize - does backfilling and compression.  Takes one more argument for the
number of successive times to backfill.  (In other words, backfills in a
repeated loop, default 1 loop per backfill attempt).  Note that the first
argument must be specified for the second argument to work correctly--if the
second is not the default, the first cannot be the default (need to specify
fifo)

delayed - compresses, but only backfills if that would cause a job to start
right away


              Comparators:

These can be given as arguments to the schedulers above.

fifo - first in, first out

largefirst - job with most required nodes first

smallfirst - job with fewest required nodes first

longfirst - job with longest estimated running time first

shortfirst - job with shortest estimated running time first

betterfit - job with most processors first, if tied longest estimated running
time, if tied first arrival time


              Machines:

simple - a simple machine, which is a bag of nodes.

mesh - a three dimensional mesh of nodes. Must take 3 arguments [x,y,z], or
two arguments [x,y] in which case z is assumed to be 1. Requires that x*y*z =
numprocs. The machine nodes are numbered first in x, then y, then z directions.
A node number 20 in a [3,4,5] machine corresponds to x=2, y=2, z=1.

torus - a three dimensional torus of nodes. The arguments are the same as mesh.

dragonfly - a dragonfly network with following arguments: [routersPerGroup,
portsPerRouter, opticalsPerRouter, nodesPerRouter, localTopology,
globalTopology]. Currently, only "all_to_all" local topology is supported.
Possible global topologies are "absolute", "circulant", and "relative".

              Allocators: 

  Note that no allocators currently require any arguments (though the linear
allocators have an optional argument)

simple - allocates any available nodes without regards for location.  Can only
be used with simple machine; does not support .alloc output file

random - chooses which nodes to allocate randomly. Can only be used with
meshmachine

genalg - the general algorithm for the nearest allocator; collects points
around a given center based on the L1 metric. Considers any free node to be a
potential center, compares them using their total pairwise L1 distance. Only
works on a 3 dimensional mesh (though one or more dimensions can be 1). Very
time-consuming on even moderate numbers of processors (several hundred).

mm - the MM allocator based on the nearest paradigm; collects points around a
given center based on the L1 metric. Considers the intersection of any two
free nodes to be a potential center, compares them using their total pairwise
L1 distance. Only works on a 3 dimensional mesh (though one or more
dimensions can be 1). The most time-consuming allocator.

mc1x1 - the MC1x1 allocator based on the nearest paradigm; collects
points around a given center based on the LInf metric. Considers any free node
to be a potential center, compares them using their total pairwise LInf
distance. Very time-consuming.

nearest - the nearest allocator, allowing customization of which point
collector, center generator, scorer, and tiebreaker is used. Very time
consuming, similarly to other Nearest allocators. The format is
nearest[centergenerator,pointcollector,scorer]  

The possible center generators are: 
all - all nodes are considered. Note that this is not used by any other
nearest allocator.  
free - all free nodes are considered 
intersect - the pairwise intersections of all free nodes are considered 

The point collectors are: 
l1 - collects points using the L1 metric 
linf - collects points using the Linf metric 
greedylinf - collects points using the Linf metric with better
awareness of the shape of the last shell.  Used in MC1x1 

The scorers are: 
l1 - scores by L1 distance from center.  Note that this is not used by any 
other nearest allocator.  
pairwise - scores by total pairwise L1 distance of a set of nodes 
linf - scores by Linf distance from center. This particular scorer can take up
to six more parameters, which are used by the tiebreaker. The format then is 
nearest[centergenerator,pointcollector,linf, maxshells, availFactor,
wallFactor, borderFactor, curvefactor,curvewidth]
Each takes a long, except maxshells which can also be assigned the value m,
which sets it to the largest signed 64 bit integer.  The defaults are
0,1,0,0,0,2. Note that the tiebreaker, and therefore the LInf scorer in
general, only work for meshes in which one of the dimensions is 1.

mbs - the MBS (or Multiple Buddy Strategy) allocator uses a block-based
approach.   The idea is to allocate the best possible square set of nodes.
This allocator and its variants are much quicker than the Nearest allocators.

granularmbs - very similar to MBS but uses granular divisions when splitting
square blocks of nodes into smaller parts

octetmbs - very similar to MBS but uses Octet divisions when splitting blocks
into smaller parts


Linear allocators - the next three allocators are based on the Linear paradigm,
which gives each node a rank based on is position along a space-filling curve.
The first argument, which is optional, specifies whether the shortest dimension
should be followed first (sort) or whether the dimensions should be followed in
the order they are given (nosort). If no argument is given the default is
nosort.  The second argument, also optional, specifies whether the curve should
be a Hilbert space-filling curve (hilbert) or a snake through the mesh (snake).
If no argument is given the default is the snake curve.  The Hilbert curve
works in both two and three dimensions regardless of size, but it works best on
a square or cube with side lengths of power 2.  In two dimensions, rectangular
and different-length meshes work fairly well; there will only be a few
discontinuities along the right border of the mesh and the successive points
will be close if not adjacent.  In three dimensions there are more
discontinuities and they are more serious.  Allocators sortedfreelist, bestfit,
and firstfit distinguish how the allocator acts once the ranks are assiged.

sortedfreelist - based on the Linear paradigm, which gives each node a rank
based on its position along a space-filling curve.  The curve must currently be
a snake.  The first and only argument, which is optional, specifies whether the
shortest dimension should be followed first (sort) or whether the dimensions
should be followed in the order they are given (nosort). If no argument is
given the default is false.  This allocator in particular picks the nodes with
the smallest rank to give to a processor, without regards to their relative
positions.  An example of a correct parameter for this allocator would be
sortedfreelist[sort].  

bestfit - based on the Linear paradigm, which gives each node a rank based on
its position along a space-filling curve.  The curve must currently be a snake.
The first and only argument, which is optional, specifies whether the shortest
dimension should be followed first (sort) or whether the dimensions should be
followed in the order they are given (nosort). If no argument is given the
default is false.  This allocator in particular looks at all sequences of empty
nodes with consecutive rank, picks the sequence with length closest to the
number of needed nodes, and allocates those processors in order.  If no single
interval is found that is large enough, it minimizes the span of processors
returned.

firstfit - based on the Linear paradigm, which gives each node a rank based on
its position along a space-filling curve. The curve must currently be a snake.
The first and only argument, which is optional, specifies whether the shortest
dimension should be followed first (sort) or whether the dimensions should be
followed in the order they are given (nosort). If no argument is given the
default is false.  This allocator in particular looks at all sequences of empty
nodes with consecutive rank, picks the first sequence with length longer than
the number of needed nodes, and allocates those processors in order.  If no
single interval is found that is large enough, it minimizes the span of
processors returned.

nearestamap - Described below among task mappers
spectralamap - Described below among task mappers

dfly* - these allocators starting with 'dfly' are published allocation policies 
that are designed specifically for systems in dragonfly topology.

dflyhybrid - This is the Level-Spread policy for dragonfly systems which spreads 
jobs within the smallest network level that a given job can fit in at the time 
of its allocation. If a job fits within the available nodes that are connected
to a single router, it selects the router with the largest number of idle nodes 
and allocates the job there. If a job cannot fit within a single router but fits 
within the available nodes in a single group, it selects the most idle group 
and allocates the job there. To further reduce load imbalance on local links in 
this group, it selects nodes connected to different routers in a round-robin 
manner. If a job cannot fit within a single group, it spreads the job throughout 
the entire network, where it selects nodes in different groups in a round-robin 
manner.

dflyjokanovic - This is the policy proposed by Jokanovic et al. and adapted to
dragonfly systems. This policy places a virtual boundary dividing the machine 
into two partitions. When allocating a job whose size is smaller than the number 
of nodes per group, the policy allocates the job to a group in the first 
partition that has enough idle nodes. When allocating larger jobs, the policy 
places the job in the second partition, starting from the last nodes.

dflyrdr - This is the Random Routers policy for dragonfly systems. It randomly 
selects a router and then selects idle nodes connected to that router following 
the label order, and repeats this step as necessary.

dflyrdg - This is the Random Group policy for dragonfly systems. It randomly 
chooses a group and selects the nodes in that group following the label order, 
and repeats this step as necessary.

dflyrrn - This is the Round Robin Nodes policy for dragonfly systems. It starts 
from the first group, selects the first idle node following the label order in 
that group, then moves to the next group and repeats the same process as 
necessary.

dflyrrr - This is the Round Robin Routers policy for dragonfly systems. It 
starts from the first group, chooses the first available router following the 
label order and selects the idle nodes connected to that router following the 
label order. It then moves to the next group and repeats the same process as 
necessary.

dflyslurm - This is the Slurm's allocation policy for dragonfly systems, 
implemented in the Slurm Workload Manager. It first attempts to allocate a 
job to the nodes connected to a single router. The first available router 
with a sufficient number of idle nodes is chosen, and the nodes connected
to that router are allocated following the label order. If there are no 
routers with a sufficient number of idle nodes, it searches for the router 
with the fewest number of idle nodes and selects the idle nodes connected to
that router following the label order, and repeats this step as necessary.


        Task Mappers: 

- simple: maps the tasks to the allocated nodes with given order
- random: maps the tasks randomly
- rcb: uses task coordinates for recursive bisection of tasks and machine nodes
- topo: uses task communication graph for recursive bisection
- rcm: uses reverse Cuthill Mckee algorithm for task mapping

Below task mappers do allocation and task mapping simultaneously. Their
allocation and mapping decisions can be used individually

- nearestamap: selects a center machine node and a center task. Expands the
mapping breadth-first in both domains. The following options are hard-coded and
can be modified by changing default parameters:
center task generation -  greedy (task #0), exhaustive (selects the task with
the least total shortest path length from all other tasks)
center node generation - greedy (first available), exhaustive (selects the node
with the closest number of available nodes within the necessary L-1 distance
sphere/diamond)
task ordering while breadth-first expansion - greedy (as the breadth-first
finds tasks), sorted (chooses the task with the most communication to the
currently allocated tasks)
- spectralamap: This algorithm uses a virtual graph, whose vertices represent
task-node mapping possibilities, and edges represent the compatibility of the
connecting vertices. The principal eigenvector of the adjacency matrix of this
graph. For more details, refer to the paper Leordeanu, M.; Hebert, M., "A
spectral technique for correspondence problems using pairwise constraints",
IEEE International Conference on Computer Vision, 2005. ICCV 2005. vol.2, 
pp.1482,1489 Vol. 2, 17-21 Oct. 2005 doi: 10.1109/ICCV.2005.20


        Fair Start Time:

The scheduler component can calculate the Fair Start Time for each job, which
analyzes the scheduling policy in terms of social justice (in short, how much
the start time of a job is affected by later arriving jobs).  A full summary
can be found in:

Avinab Rajbhandary, David P. Bunde, and Vitus J. Leung. "Variations of
Conservative to improve fairness".

G. Sabin and P. Sadayappan. "Unfairness metrics for space-sharing parallel job
schedulers". In Proc. 11th Workshop Job Scheduling Strategies for Parallel
Processing, number 3834 in LNCS, pages 238–256, 2005.

There are two kinds of FST, strict and relaxed.  Strict FST runs a simulation
of the scheduler when a given job arrives and makes note of when the job starts
(note that no later jobs are considered in this simulation since they have not
arrived yet).  Relaxed FST does the same, but does not allow the arriving job
to be scheduled until all other jobs have already been scheduled.  The
advantage of relaxed FST is that strict FST may give start times that are not
feasible when considering the entire schedule.

Thus, the three options for FST in the sdl are strict, relaxed, or none.  If
there is no specified value the scheduler defaults to none.  If a value is
specified, the FST for each job is stored in *.sim.time.  No overall
calculations (i.e. average or maximum (actualStartTime - FST)) are performed.

An example of the sdl file with strict FST calculations would be

./makeSDL.pl 4008 LLNL.sim easy["largefirst"] mesh[24,167] random strict > testsdl.sdl 


        Heat Recirculation Matrix (D_Matrix):

The scheduler accepts heat recirculation matrix in matrix market format for the
energy allocator (For details on D_Matrix, refer to Tang, Q.; Gupta, S. K S;
Varsamopoulos, G., "Energy-Efficient Thermal-Aware Task Scheduling for
Homogeneous High-Performance Computing Data Centers: A Cyber-Physical
Approach", IEEE Transactions on Parallel and Distributed Systems, vol.19,no.11,
pp.1458,1472, Nov. 2008 doi: 10.1109/TPDS.2008.111)


        Allocation Based Timing:

The scheduler component can change the runtime of jobs based on their
allocation.  Currently, this is based on the sum of the L1 distance between
each pair of nodes allocated for the job.  Therefore, a mesh is required for
this metric to be used.  

The details are given in the parameter <timeperdistance> in the sdl file.  The
format is a[b,c]; then the total time for a job is

BaselineRunningTime * (1 + a * pow(hop-bytes, (b + c * r))

Where BaselineRunningTime of a job is calculated assuming that the same job is
allocated to the smallest possible rectangular mesh and its tasks are mapped
in-order (simple task mapper). r is a random number uniformly distributed
between -1 and 1.

An important detail is that this may be larger than the Estimated Worst-case
Execution Time for some jobs. If this happens, SST does throws an error.
